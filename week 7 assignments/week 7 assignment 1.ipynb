{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b708ca-3ad8-4253-924f-9aefbeed1629",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335ad93-8ce1-4e8b-8397-ab254e538a4d",
   "metadata": {},
   "source": [
    "Web scraping is the automated process of extracting data from websites for analysis or other purposes. It’s used for data collection in areas like market research, price comparison, and sentiment analysis on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbbcde-711c-4a6a-b59a-1d57f159b669",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a787f-ebba-4e83-a3d9-93cddab1e0b5",
   "metadata": {},
   "source": [
    "Common web scraping methods include HTML parsing (using libraries like BeautifulSoup), API requests (accessing structured data directly), and browser automation (using tools like Selenium for dynamic content)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7e054-8357-4d61-8df3-5b9d0d028ade",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e2fd5-bdc7-499e-9148-d9d0088e817d",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents, making it easy to navigate, search, and modify web content. It’s widely used in web scraping to extract specific data from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230980df-6748-4981-8091-5df931d9de4e",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b68dd-2f5c-4f90-a7bc-cfc25eecaea6",
   "metadata": {},
   "source": [
    "Flask is used in a web scraping project to create a web interface, allowing users to interact with the scraper and view results. It helps in serving the scraped data dynamically on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c9939-1374-4ea8-b1f8-fe7a9761e50e",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46597652-e9cf-4c63-b8a8-6e6f501ac85c",
   "metadata": {},
   "source": [
    "In this project, AWS Elastic Beanstalk and AWS CodePipeline are used:\n",
    "\n",
    "Elastic Beanstalk: This service simplifies application deployment and management by automatically handling infrastructure provisioning, load balancing, scaling, and monitoring for the web application.\n",
    "CodePipeline: It automates the build, test, and deployment process, enabling continuous integration and delivery (CI/CD) to streamline code updates and ensure rapid and reliable application delivery."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
