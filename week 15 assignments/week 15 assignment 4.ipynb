{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3b7ad6-7ce9-4981-84be-20d2f5bf8e81",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb64fa-2e2c-4415-94c9-b54877981c40",
   "metadata": {},
   "source": [
    "Lasso Regression is a linear regression model that includes a penalty term proportional to the sum of the absolute values of the coefficients. promoting sparsity by shrinking some coefficients to zero, aiding in feature selection.OLS Regression does not include any regularization, which can lead to overfitting.\n",
    "Ridge Regression includes an L2 penalty, shrinking coefficients but not setting them to zero, thereby retaining all features.\n",
    "Elastic Net Regression combines L1 and L2 penalties, balancing feature selection and stability.\n",
    "These differences make Lasso Regression particularly useful in scenarios where feature selection is important, and when dealing with high-dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb2162-0fac-41d8-879d-4a7eaf4588a9",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f831da-5603-4fdf-8d80-3c6facaa8a73",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is its ability to shrink some coefficients to exactly zero. This characteristic effectively selects a subset of the features, which simplifies the model by including only the most important predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0432968-a39d-462c-b135-6e47d495d09a",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528be90-2462-418a-8762-dd309917b2e8",
   "metadata": {},
   "source": [
    "Interpreting the coefficients of a Lasso Regression model involves understanding the magnitude and sign of the non-zero coefficients, the impact of regularization on feature selection, and the context of the problem. The coefficients provide insights into the relationships between predictors and the response variable, with zero coefficients indicating features that are not influential in the presence of the regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ffb0a-81e1-4d0d-a530-dde2e65d91ee",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66960d7f-4807-4ccb-841f-61e9ae825aed",
   "metadata": {},
   "source": [
    "The main tuning parameter in Lasso Regression is the regularization parameter Œª, which controls the trade-off between model complexity and fitting accuracy. Adjusting  ùúÜ\n",
    "affects the model's ability to prevent overfitting and underfitting, with cross-validation commonly used to find the optimal value. Properly tuning ùúÜ and scaling the features are crucial for building an effective Lasso Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a7d44-45e9-41f7-834e-fe2b49d69bd4",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85dc64-07aa-44a6-bf95-b1817247cfff",
   "metadata": {},
   "source": [
    "While Lasso Regression is inherently linear, it can be adapted to non-linear problems by transforming the features using polynomial features, basis functions, interaction terms, or kernel methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c71c2-4a62-4378-96ad-376e5b37184f",
   "metadata": {},
   "source": [
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f91e5d-54f6-4938-9861-c8f668694a39",
   "metadata": {},
   "source": [
    "Both Ridge and Lasso Regression help in preventing overfitting by adding a penalty term to the regression model. The choice between them depends on the specific problem and the nature of the data. Ridge Regression is useful when you want to retain all features, while Lasso Regression is beneficial for feature selection and creating simpler, more interpretable models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539262c-c8e0-4190-9e53-1b3956916a9e",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8b8db-c51d-4add-a990-fbdb7a7274ef",
   "metadata": {},
   "source": [
    "Lasso Regression handles multicollinearity by performing feature selection, often selecting one variable from a group of highly correlated variables and shrinking the rest to zero. This reduces redundancy and simplifies the model. However, the selection process can be unstable in the presence of highly correlated features, and the introduction of bias may affect interpretability. In cases where multicollinearity is a significant concern and feature selection is desired, Elastic Net offers a hybrid approach that combines the strengths of both Lasso and Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e79855-2898-4baa-95eb-2c733925f3e0",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29117-610c-48ac-af74-686d9c9b4d5c",
   "metadata": {},
   "source": [
    "the optimal Œª in Lasso Regression involves using cross-validation to find the value that minimizes the cross-validation error. This ensures that the model generalizes well to new data by balancing bias and variance. Tools like LassoCV in scikit-learn make this process straightforward by automating the cross-validation and model fitting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7d35b-94db-4f0f-a3a8-9972079baaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
